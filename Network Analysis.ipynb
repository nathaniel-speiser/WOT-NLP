{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "induced-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "import pickle\n",
    "from textblob import TextBlob\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "sapphire-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('char_list.pkl', 'rb') as f:\n",
    "    char_list = pickle.load(f)\n",
    "all_books_nosw_singularized = pd.read_pickle('data/allbooks_sing_nosw.pkl')\n",
    "\n",
    "important_chars = ['rand', 'perrin', 'mat', 'egwene', 'elayne', 'nynaeve', 'moiraine', 'min', 'faile', 'aviendha',\n",
    "                  'gawyn', 'lan', 'siuan', 'morgase', 'cadsuane', 'ituralde', 'galad', 'pevara', 'tuon', 'elaida', \n",
    "                  'androl', 'taim', 'logain', 'gareth', 'rhuarc', 'graendal', 'moridin', 'moghedien', 'verin', \n",
    "                  'birgitte', 'loial', 'tam', 'demandred', 'sammael', 'moridin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "approximate-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chars_in_chapter(split_text, char_list):\n",
    "    return [char for char in char_list if char in split_text]\n",
    "\n",
    "def get_appearances(split_text, chars_in_chapter, graph_dict, indices_dict):\n",
    "    \"\"\"\n",
    "    Get the number of appearances for all characters in a chapter and place the list of appearances into a dict\n",
    "    \n",
    "    \"\"\"\n",
    "    text_array = np.array(split_text)\n",
    "    for char in chars_in_chapter:\n",
    "        char_indices = np.where(text_array == char)[0]\n",
    "        graph_dict[char] = len(char_indices)\n",
    "        indices_dict[char] = char_indices\n",
    "\n",
    "def get_all_interactions(chars_in_chapter, threshold, graph_dict, indices_dict):\n",
    "    all_pairs = itertools.combinations(chars_in_chapter, 2)\n",
    "    for pair in all_pairs:\n",
    "        num_interactions = get_num_interactions( *pair, indices_dict, threshold)\n",
    "        if num_interactions > 1:\n",
    "            graph_dict[pair] = num_interactions\n",
    "\n",
    "def get_num_interactions(char1, char2, indices_dict, threshold):\n",
    "    char1_indices = indices_dict[char1]\n",
    "    char2_indices = indices_dict[char2]\n",
    "    interaction_distances = np.array([abs(interaction[0]-interaction[1]) for interaction in itertools.product(char1_indices,\n",
    "                                                                                                    char2_indices)])\n",
    "    num_interactions = len(np.where(interaction_distances <= threshold)[0])\n",
    "    return num_interactions\n",
    "    \n",
    "def find_chapter_interactions(text, char_list, threshold):\n",
    "    graph_dict = {}\n",
    "    indices_dict = {}\n",
    "    split_text = text.split()\n",
    "    \n",
    "    characters_in_chapter = get_chars_in_chapter(split_text, char_list)\n",
    "    \n",
    "    get_appearances(split_text, characters_in_chapter, graph_dict, indices_dict)\n",
    "    \n",
    "    get_all_interactions(characters_in_chapter, threshold, graph_dict,indices_dict)\n",
    "    return graph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "romantic-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_graphs(graph1, graph2):\n",
    "    \n",
    "    if not graph1:\n",
    "        return graph2\n",
    "    if not graph2:\n",
    "        return graph1\n",
    "    \n",
    "    combined_graph = graph1.copy()\n",
    "    for key, val in graph2.items():\n",
    "        if key not in combined_graph.keys():\n",
    "            combined_graph[key] = val\n",
    "        else: combined_graph[key] +=val\n",
    "    return combined_graph\n",
    "\n",
    "def add_graphs_from_list(graph_list):\n",
    "    combined_graph = graph_list[0]\n",
    "    for new_graph in graph_list[1:]:\n",
    "        combined_graph=add_graphs(combined_graph, new_graph)\n",
    "    return combined_graph\n",
    "\n",
    "def make_cumulative_graphs(graph_list):\n",
    "    cumulative_graph_list = []\n",
    "    \n",
    "    cumulative_graph = graph_list[0]\n",
    "    cumulative_graph_list.append(cumulative_graph.copy())\n",
    "    \n",
    "    for new_graph in graph_list[1:]:\n",
    "        cumulative_graph=add_graphs(cumulative_graph, new_graph)\n",
    "        cumulative_graph_list.append(cumulative_graph.copy())\n",
    "        \n",
    "    return cumulative_graph_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "rational-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_graph(graph_dict):\n",
    "    graph = nx.Graph()\n",
    "    for key in graph_dict:\n",
    "        if type(key) is str:\n",
    "            graph.add_node(key, size = graph_dict[key])\n",
    "        if type(key) is tuple:\n",
    "            graph.add_edge(*key, weight = graph_dict[key])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "outside-possibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5790ebc03efe43c594f18dbf375bdcf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/677 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graphs = pd.DataFrame()\n",
    "\n",
    "graphs['chapter_title'] = all_books_nosw_singularized['chapter_title']\n",
    "graphs['cumulative_chapter_number'] = all_books_nosw_singularized['cumulative_chapter_number']\n",
    "\n",
    "graphs['chapter_graph'] = all_books_nosw_singularized.progress_apply(lambda x: find_chapter_interactions(x['text'],important_chars,20),axis=1)\n",
    "\n",
    "graphs['cumulative_graphs'] = make_cumulative_graphs(graphs['chapter_graph'])\n",
    "\n",
    "\n",
    "\n",
    "G = dict_to_graph(graphs['cumulative_graphs'][676])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "interracial-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph1 = dict_to_graph(graphs['cumulative_graphs'][676])\n",
    "graph2 = dict_to_graph(graphs['cumulative_graphs'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "funded-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_edge_weights(graph):\n",
    "    g = graph.copy()\n",
    "    original_weights = []\n",
    "    for edge in g.edges():\n",
    "        original_weights.append(g.edges()[edge]['weight'])\n",
    "    scaler = MinMaxScaler(feature_range=(.1,8))\n",
    "    new_weights = scaler.fit_transform(np.array(original_weights).reshape(-1,1)).flatten()\n",
    "    for i,edge in enumerate(g.edges()):\n",
    "        g.edges()[edge]['weight'] = new_weights[i]\n",
    "    return g\n",
    "\n",
    "def plot_network(graph, save = False, fname = 'graph'):\n",
    "    scaled = scale_edge_weights(graph)\n",
    "    pos = nx.spring_layout(graph, k =.5 , seed = 1)\n",
    "    \n",
    "    edge_traces = []\n",
    "    for edge in scaled.edges():\n",
    "        char1  = edge[0]\n",
    "        char2  = edge[1]\n",
    "        x0, y0 = pos[char1]\n",
    "        x1, y1 = pos[char2]\n",
    "        trace  = make_edge([x0, x1, None], [y0, y1, None], scaled.edges()[edge]['weight'])\n",
    "        edge_traces.append(trace)\n",
    "        \n",
    "    \n",
    "    node_trace = go.Scatter(x         = [],\n",
    "                        y         = [],\n",
    "                        text      = [],\n",
    "                        textposition = \"top center\",\n",
    "                        textfont_size = 20,\n",
    "                        mode      = 'markers+text',\n",
    "                        hoverinfo = 'none',\n",
    "                        marker    = dict(color = [],\n",
    "                                         size  = [],\n",
    "                                         line  = None))\n",
    "    for node in scaled.nodes():\n",
    "        x, y = pos[node]\n",
    "        node_trace['x'] += tuple([x])\n",
    "        node_trace['y'] += tuple([y])\n",
    "        node_trace['marker']['color'] += tuple(['DarkSlateBlue'])\n",
    "        node_trace['marker']['size'] += tuple([20])#tuple([np.log(scaled.nodes()[node]['size'])])\n",
    "        node_trace['text'] += tuple([node.capitalize()])\n",
    "        \n",
    "        \n",
    "    layout = go.Layout(paper_bgcolor='rgba(0,0,0,0)',plot_bgcolor='rgba(0,0,0,0)')\n",
    "    fig = go.Figure(layout = layout)\n",
    "    \n",
    "    for trace in edge_traces:\n",
    "        fig.add_trace(trace)\n",
    "    fig.add_trace(node_trace)\n",
    "    \n",
    "    fig.update_layout(showlegend = False, width = 2000, height = 2000)\n",
    "    fig.update_xaxes(showticklabels = False)\n",
    "    fig.update_yaxes(showticklabels = False)\n",
    "    \n",
    "    if save:\n",
    "        fig.write_image('network_graphs/'+fname+'.png')\n",
    "    else:\n",
    "        py.plot(fig, filename='test.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "assumed-shoot",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_network(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "minus-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_network(graph1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "presidential-syndrome",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,graph_dict in enumerate(graphs['cumulative_graphs'][650:]):\n",
    "    graph = dict_to_graph(graph_dict)\n",
    "    plot_network(graph, save=True, fname = f'chap{i}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "announced-albuquerque",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085c51b8778a4092b4279f173f50c7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=13, description='chap_num', max=26), Output()), _dom_classes=('widget-inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "@interact\n",
    "def show_pics(chap_num = (0,26,1)):\n",
    "    display(Image(f'network_graphs/chap{chap_num}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "heavy-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_edge(x, y, width):\n",
    "    \n",
    "    '''Creates a scatter trace for the edge between x's and y's with given width\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x    : a tuple of the endpoints' x-coordinates in the form, tuple([x0, x1, None])\n",
    "    \n",
    "    y    : a tuple of the endpoints' y-coordinates in the form, tuple([y0, y1, None])\n",
    "    \n",
    "    width: the width of the line\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    An edge trace that goes between x0 and x1 with specified width.\n",
    "    '''\n",
    "    return  go.Scatter(x         = x,\n",
    "                       y         = y,\n",
    "                       line      = dict(width = width,\n",
    "                                   color = 'cornflowerblue'),\n",
    "                       mode      = 'lines')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
